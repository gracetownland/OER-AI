# Database Migrations

This document provides comprehensive information about the database migration system used in the OER-AI Assistant project.

## Table of Contents

1. [Overview](#overview)
2. [Quick Start](#quick-start)
3. [Migration System Architecture](#migration-system-architecture)
4. [Migration Files Structure](#migration-files-structure)
5. [How Migrations Work](#how-migrations-work)
6. [Creating New Migrations](#creating-new-migrations)
7. [Common Migration Patterns](#common-migration-patterns)
8. [Running Migrations](#running-migrations)
9. [Migration Patterns and Best Practices](#migration-patterns-and-best-practices)

## Overview

The OER-AI project uses a `node-pg-migrate` system to manage database schema changes with numbered JavaScript files. This provides a reliable, trackable, and automated approach to database schema evolution throughout the project lifecycle.

## Quick Start

### Creating a New Migration

1. **Find the next migration number:**

   ```bash
   ls cdk/lambda/db_setup/migrations/ | tail -1
   # Use next sequential number (e.g., if last is 008, use 009)
   ```

2. **Create migration file:**

   ```bash
   # Replace XXX with next number and describe_change with description
   touch cdk/lambda/db_setup/migrations/XXX_describe_change.js
   ```

3. **Basic migration template:**

   ```javascript
   exports.up = (pgm) => {
     // Your migration code here
     pgm.sql(`
       -- Your SQL here
     `);
   };

   exports.down = (pgm) => {
     // Optional: rollback logic
   };
   ```

## Migration System Architecture

The migration system is built on `node-pg-migrate` and consists of:

- **Migration Files**: Located in `cdk/lambda/db_setup/migrations/` with numbered JavaScript files
- **Migration Runner**: The `index.js` file contains the main migration execution logic
- **Migration Tracking**: Uses a `pgmigrations` table to track which migrations have been applied
- **Automatic Execution**: Runs during CDK deployments via AWS Lambda

### Key Components

```
cdk/lambda/db_setup/
├── index.js              # Main entry point, runs node-pg-migrate
├── initializer.py        # Database initialization utilities
└── migrations/           # Migration files directory
    ├── 000_initial_schema.js
    ├── 001_update_year_to_publish_date.js
    ├── 002_update_sections_and_media_items.js
    ├── 003_refactor_session_relationships.js
    └── ...
```

## Migration Files Structure

### JavaScript Migration Files

Each migration file follows this naming convention: `{number}_{description}.js`

**Example Structure:**

```javascript
exports.up = (pgm) => {
  // Forward migration logic
  pgm.sql(`
    ALTER TABLE users ADD COLUMN new_field VARCHAR(255);
  `);
};

exports.down = (pgm) => {
  // Rollback logic (optional but recommended)
  pgm.sql(`
    ALTER TABLE users DROP COLUMN new_field;
  `);
};
```

### Common Migration Operations

#### Adding Tables

```javascript
exports.up = (pgm) => {
  pgm.createTable("new_table", {
    id: {
      type: "uuid",
      primaryKey: true,
      default: pgm.func("uuid_generate_v4()"),
    },
    name: { type: "varchar", notNull: true },
    created_at: { type: "timestamp", default: pgm.func("now()") },
  });
};
```

#### Adding Columns

```javascript
exports.up = (pgm) => {
  pgm.addColumn("existing_table", {
    new_column: {
      type: "jsonb",
      default: "{}",
      comment: "Description of the column purpose",
    },
  });
};
```

#### Modifying Columns

```javascript
exports.up = (pgm) => {
  pgm.sql(`
    ALTER TABLE table_name ALTER COLUMN column_name TYPE new_type;
  `);
};
```

## How Migrations Work

### Execution Flow

1. **Migration Discovery**: The system scans the `migrations/` directory for `.js` files
2. **Sorting**: Files are sorted numerically by their prefix (e.g., `001_`, `002_`)
3. **Tracking Check**: Each migration is checked against the `pgmigrations` table
4. **Execution**: Only unapplied migrations are executed in order
5. **Recording**: Successfully applied migrations are recorded in the tracking table

### Migration Tracking

The system uses a PostgreSQL table to track applied migrations:

- **`pgmigrations`**: Used by node-pg-migrate to track which migrations have been successfully applied

### Deployment Process

```mermaid
graph TD
    A[Lambda Function Triggered] --> B[Connect to Database]
    B --> C[Run node-pg-migrate]
    C --> D[Check Migration Files]
    D --> E[Apply Pending Migrations]
    E --> F[Create Application Users]
    F --> G[Update Secrets Manager]
    G --> H[Return Success]
```

## Creating New Migrations

### Method 1: JavaScript Migration Files (Recommended)

1. **Determine the next migration number:**

   ```bash
   # Look at existing files in migrations/ directory
   ls cdk/lambda/db_setup/migrations/
   # Use the next sequential number
   ```

2. **Create the migration file:**

   ```bash
   # Example: Adding user preferences table
   touch cdk/lambda/db_setup/migrations/009_user_preferences.js
   ```

3. **Write the migration:**

   ```javascript
   exports.up = (pgm) => {
     pgm.createTable("textbook_favorites", {
       id: {
         type: "uuid",
         primaryKey: true,
         default: pgm.func("uuid_generate_v4()"),
       },
       user_session_id: {
         type: "uuid",
         notNull: true,
         references: "user_sessions(id)",
         onDelete: "CASCADE",
       },
       textbook_id: {
         type: "uuid",
         notNull: true,
         references: "textbooks(id)",
         onDelete: "CASCADE",
       },
       created_at: { type: "timestamp", default: pgm.func("now()") },
     });

     // Add indexes
     pgm.createIndex("textbook_favorites", "user_session_id");
     pgm.createIndex("textbook_favorites", "textbook_id");
   };

   exports.down = (pgm) => {
     pgm.dropTable("textbook_favorites");
   };
   ```

## Common Migration Patterns

### Adding a New Table

```javascript
exports.up = (pgm) => {
  pgm.createTable("table_name", {
    id: {
      type: "uuid",
      primaryKey: true,
      default: pgm.func("uuid_generate_v4()"),
    },
    name: { type: "varchar", notNull: true },
    description: { type: "text" },
    status: {
      type: "varchar",
      default: "active",
      check: "status IN ('active', 'inactive')",
    },
    created_at: { type: "timestamp", default: pgm.func("now()") },
    updated_at: { type: "timestamp" },
  });

  // Add indexes
  pgm.createIndex("table_name", "name");
};
```

### Adding Columns

```javascript
exports.up = (pgm) => {
  pgm.addColumns("existing_table", {
    new_column: {
      type: "varchar",
      default: "default_value",
      notNull: true,
      comment: "Description of the column",
    },
    optional_column: {
      type: "jsonb",
      default: "{}",
    },
  });
};
```

### Modifying Columns

```javascript
exports.up = (pgm) => {
  // Change column type
  pgm.sql(`ALTER TABLE table_name ALTER COLUMN column_name TYPE new_type;`);

  // Add constraint
  pgm.sql(
    `ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`
  );

  // Set default value
  pgm.sql(
    `ALTER TABLE table_name ALTER COLUMN column_name SET DEFAULT 'value';`
  );
};
```

### Adding Foreign Keys

```javascript
exports.up = (pgm) => {
  pgm.addColumns("child_table", {
    parent_id: {
      type: "uuid",
      references: "parent_table(id)",
      onDelete: "CASCADE",
      onUpdate: "CASCADE",
    },
  });

  // Or add constraint to existing column
  pgm.addConstraint("child_table", "fk_parent", {
    foreignKeys: {
      columns: "parent_id",
      references: "parent_table(id)",
      onDelete: "SET NULL",
    },
  });
};
```

### Creating Indexes

```javascript
exports.up = (pgm) => {
  // Simple index
  pgm.createIndex("table_name", "column_name");

  // Composite index
  pgm.createIndex("table_name", ["col1", "col2"], {
    name: "idx_custom_name",
  });

  // Unique index
  pgm.createIndex("table_name", "email", {
    unique: true,
    name: "idx_unique_email",
  });

  // Partial index
  pgm.createIndex("table_name", "status", {
    where: "status = 'active'",
    name: "idx_active_status",
  });
};
```

### Working with ENUMs

```javascript
exports.up = (pgm) => {
  // Create ENUM type safely
  pgm.sql(`
    DO $$ BEGIN
        CREATE TYPE status_type AS ENUM ('pending', 'active', 'inactive');
    EXCEPTION
        WHEN duplicate_object THEN null;
    END $$;
  `);

  // Use in table
  pgm.addColumn("table_name", {
    status: {
      type: "status_type",
      default: "pending",
    },
  });
};
```

### Adding Extensions

```javascript
exports.up = (pgm) => {
  pgm.sql(`CREATE EXTENSION IF NOT EXISTS "uuid-ossp";`);
  pgm.sql(`CREATE EXTENSION IF NOT EXISTS "vector";`);
};
```

### Data Migrations

```javascript
exports.up = (pgm) => {
  // Insert default data
  pgm.sql(`
    INSERT INTO system_settings (key, value) VALUES 
      ('max_token_limit', '4000'),
      ('default_model', 'meta.llama3-70b-instruct-v1:0')
    ON CONFLICT (key) DO NOTHING;
  `);

  // Update existing data
  pgm.sql(`
    UPDATE textbooks 
    SET status = 'Active' 
    WHERE status IS NULL;
  `);
};
```

## Running Migrations

### Automatic Execution

Migrations run automatically during:

- **CDK deployment**: When the database setup Lambda function is triggered
- **Database initialization**: First-time database setup
- **Stack updates**: When infrastructure changes are deployed

### Manual Execution (Development)

For development or troubleshooting:

```bash
# Navigate to the lambda directory
cd cdk/lambda/db_setup

# Install dependencies
npm install

# Run migrations directly using node-pg-migrate
node -e "
const { migrate } = require('node-pg-migrate');
migrate({
  databaseUrl: 'postgresql://user:pass@host:5432/db',
  dir: './migrations',
  direction: 'up'
}).then(() => console.log('Done'));
"
```

## Safety Guidelines

### Always Use These Patterns

```javascript
// ✅ Safe table creation
CREATE TABLE IF NOT EXISTS table_name (...);

// ✅ Safe column addition with default
pgm.addColumn('table', {
  column: { type: 'varchar', default: 'value', notNull: true }
});

// ✅ Safe ENUM creation
DO $$ BEGIN
    CREATE TYPE enum_name AS ENUM ('val1', 'val2');
EXCEPTION
    WHEN duplicate_object THEN null;
END $$;

// ✅ Safe index creation
CREATE INDEX IF NOT EXISTS idx_name ON table (column);
```

### Avoid These Patterns

```javascript
// ❌ Dangerous: Non-nullable without default
pgm.addColumn('table', {
  required_field: { type: 'varchar', notNull: true } // Will fail on existing rows
});

// ❌ Dangerous: Dropping columns (data loss)
pgm.dropColumn('table', 'column');

// ❌ Dangerous: Dropping tables (data loss)
pgm.dropTable('table');

// ❌ Dangerous: Raw SQL without IF NOT EXISTS
CREATE TABLE table_name (...); // Will fail if table exists
```

## Migration Patterns and Best Practices

### 1. Safety First

- **Always use `IF NOT EXISTS`** for CREATE statements
- **Handle duplicate objects gracefully** using `DO $$ BEGIN ... EXCEPTION WHEN duplicate_object THEN null; END $$;`
- **Test migrations in development** before applying to production

### 2. Data Integrity

```javascript
// Good: Safe column addition with default
exports.up = (pgm) => {
  pgm.addColumn("textbooks", {
    status: {
      type: "varchar",
      default: "Disabled",
      notNull: true,
    },
  });
};

// Avoid: Non-nullable column without default
exports.up = (pgm) => {
  pgm.addColumn("textbooks", {
    required_field: { type: "varchar", notNull: true }, // This will fail!
  });
};
```

### 3. Index Management

```javascript
exports.up = (pgm) => {
  // Add table first
  pgm.createTable("large_table", {
    /* ... */
  });

  // Then add indexes
  pgm.createIndex("large_table", "frequently_queried_column");
  pgm.createIndex("large_table", ["composite", "index"], {
    name: "idx_composite_key",
  });
};
```

### 4. Type Safety

```javascript
// Good: Handle ENUM types safely
exports.up = (pgm) => {
  pgm.sql(`
    DO $$ BEGIN
        CREATE TYPE new_status AS ENUM ('pending', 'active', 'inactive');
    EXCEPTION
        WHEN duplicate_object THEN null;
    END $$;
  `);
};
```

### 5. Foreign Key Constraints

```javascript
exports.up = (pgm) => {
  pgm.createTable("child_table", {
    id: { type: "uuid", primaryKey: true },
    parent_id: {
      type: "uuid",
      references: "parent_table(id)",
      onDelete: "CASCADE", // or 'SET NULL', 'RESTRICT'
      onUpdate: "CASCADE",
    },
  });
};
```

### 6. Large Data Migrations

For migrations involving large datasets:

```javascript
exports.up = (pgm) => {
  // Use batch processing for large updates
  pgm.sql(`
    UPDATE large_table 
    SET new_column = old_column 
    WHERE id IN (
      SELECT id FROM large_table 
      WHERE new_column IS NULL 
      LIMIT 1000
    );
  `);
};
```

## Migration States and Lifecycle

### Migration States

1. **Pending**: Migration file exists but hasn't been applied
2. **Applied**: Migration has been successfully executed and recorded
3. **Failed**: Migration encountered an error during execution

### Rollback Considerations

- **Forward-only approach**: The system primarily supports forward migrations
- **Manual rollbacks**: Rollback procedures must be handled manually if needed
- **Data loss prevention**: Always backup before major schema changes

### Best Practices Summary

1. **Use sequential numbering** for migration files
2. **Always use IF NOT EXISTS** for CREATE statements
3. **Provide defaults** when adding NOT NULL columns
4. **Test migrations** on development database first
5. **Keep migrations focused** - one logical change per file
6. **Add appropriate indexes** for new columns that will be queried
7. **Document complex migrations** with comments
8. **Consider performance** for large table modifications
9. **Plan rollback strategy** for critical changes
10. **Backup production** before major schema changes

## Getting Help

- Review existing migrations for patterns: `cdk/lambda/db_setup/migrations/`
- Test in development environment first
- Ask team for review of complex migrations
- Check PostgreSQL documentation for advanced SQL features

This comprehensive migration system ensures safe, trackable, and reliable database schema evolution throughout the OER-AI project lifecycle.
